---
layout: article
title: DeepFM论文阅读笔记
mathjax: true
tags: 机器学习
---

## 概括

DeepFM模型是华为诺亚实验室于2017年发布的推荐系统模型（[论文链接](https://arxiv.org/pdf/1703.04247.pdf)）。这篇文章是基于Google的[Wide & Deep模型](/_posts/2021-01-08-Wide_and_Deep.md)的改进和提升，被广泛的应用在工程推荐系统上。

DeepFM是基于Wide & Deep模型思想的，因此模型的结构也是同样用一个浅层模型来提取记忆，即出现过的特征组合，一个深层模型负责泛化，即搜索新的特征组合。DeepFM对于Wide & Deep的改进主要有：

1. Wide模型由LR修改成了FM（Factor Machine），FM可以起到自动学习交叉特征的作用，避免了外积交叉特征工程部分。
2. 共享原始输入特征，原始的特征即用在Wide模型，又用在Deep模型上，也是为了简化特征工程。

DeepFM和其他推荐系统模型比较：

![DeepFM Comparison](/assets/images/posts/DeepFMComparison.png)


## 模型结构

DeepFM分为FM和DNN两部分，就像前面讨论的，这两部分共享相同的输入权重 。对于一个简单一阶特征$i$, 用一个标量 $\omega_{i}$来描述特征权重,同时引入一个**隐向量$V_{i}$** 来描述这个特征和其他特征之间的交互性影响，并构造FM模型以期待模型自动学习出这个特征的隐向量表达$V_{i}$. 

模型的训练过程类似Wide & Deep, Wide模型和Deep模型联合训练，联合训练的模型的表达式：

$$
\hat{y} = sigmoid(y_{FM} + y_{DNN})
$$

* FM模型
  
  FM模型的结构如图所示。相比于Wide & Deep的特征外积只能在连两个特征同时显性出现，FM这种隐向量表达的方法更适用于挖掘更深层次的特征耦合。

    ![FM Componet](/assets/images/posts/DeepFM-FM.png)

  FM部分的输出表达式写作：
  $$
    y_{FM} = <\omega, x> + \sum_{j_1=1}^{d}\sum_{j_2=j_1+1}^{d}<V_{j_1}, V_{j_2}>x_{j_1} \cdot x_{j_2}
  $$

* DNN模型
  
  DNN模型的结构如图所示。CTR模型的输入向量大部分都是非常稀疏的，因此必须引入Embeddeding层。DeepFM的Embedding层的设计有下面的特点：（1）输入维度可以不同，输出维度必须相同；（2）FM模型中，特征$i$的隐向量$V_{i}$被复用到DNN模型作为特征压缩的权重。这一点很重要，也是DeepFM模型的精髓，FM部分的权重是通过FM和DNN模型整体训练出来的，而不是单独用FM模型训练再利用的。

    ![DNN Componet](/assets/images/posts/DeepFM-DNN.png)


## 一些总结

DeepFM从推出后在工业界的得到了广泛的应用，其先进的思想主要是用FM模型来替代Wide & Deep模型中的Wide部分。而FM训练的隐向量，刚好又被用来作为Deep模型里面的特征表达向量，从而避免了复杂的特征工程，真正实现了end-to-end的推荐系统。
